{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2pZGXIaXHHO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "INPUT_PATH  = \"/content/drive/MyDrive/dijalekti/texts_clean.jsonl\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/dijalekti/texts_segmented.jsonl\"\n",
        "\n",
        "print(\"Вчитуваме оригинални текстови од:\", INPUT_PATH)\n",
        "\n",
        "records = []\n",
        "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        obj = json.loads(line)\n",
        "        text = (obj.get(\"text\") or \"\").strip()\n",
        "        dialect = (obj.get(\"dialect\") or \"\").strip()\n",
        "        if text != \"\" and dialect != \"\":\n",
        "            records.append((text, dialect))\n",
        "\n",
        "print(\"Оригинален број текстови:\", len(records))\n",
        "\n",
        "def split_into_chunks(text,\n",
        "                      min_words=10,\n",
        "                      max_words=60):\n",
        "    \"\"\"\n",
        "    1) Го дели текстот на реченици\n",
        "    2) Ги групира речениците во сегменти со должина помеѓу min_words и max_words\n",
        "    \"\"\"\n",
        "\n",
        "    sentences = re.split(r'(?<=[\\.\\?\\!])\\s+|\\n+', text)\n",
        "    sentences = [s.strip() for s in sentences if s.strip() != \"\"]\n",
        "\n",
        "    chunks = []\n",
        "    current = []\n",
        "    current_len = 0\n",
        "\n",
        "    for sent in sentences:\n",
        "        words = sent.split()\n",
        "        n = len(words)\n",
        "\n",
        "        if n >= max_words:\n",
        "            if current_len >= min_words:\n",
        "                chunks.append(\" \".join(current))\n",
        "                current = []\n",
        "                current_len = 0\n",
        "            chunks.append(sent)\n",
        "            continue\n",
        "\n",
        "        if current_len + n > max_words and current_len >= min_words:\n",
        "            chunks.append(\" \".join(current))\n",
        "            current = []\n",
        "            current_len = 0\n",
        "\n",
        "        current.append(sent)\n",
        "        current_len += n\n",
        "\n",
        "    if current_len >= min_words:\n",
        "        chunks.append(\" \".join(current))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "segmented = []\n",
        "for text, dialect in records:\n",
        "    chunks = split_into_chunks(text,\n",
        "                               min_words=10,\n",
        "                               max_words=60)\n",
        "    for ch in chunks:\n",
        "        segmented.append({\n",
        "            \"text\": ch,\n",
        "            \"dialect\": dialect\n",
        "        })\n",
        "\n",
        "print(\"Број сегменти по сечење:\", len(segmented))\n",
        "\n",
        "cnt = Counter([r[\"dialect\"] for r in segmented])\n",
        "print(\"Број сегменти по дијалект:\")\n",
        "for d, c in cnt.items():\n",
        "    print(f\"{d}: {c}\")\n",
        "\n",
        "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    for obj in segmented:\n",
        "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"Новиот сегментиран датасет е снимен во:\", OUTPUT_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WksUxiipXeK_",
        "outputId": "de5a7c7c-ff49-4676-a798-f612268df99f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Вкупно сегменти: 4975\n",
            "Број сегменти по дијалект (пред филтрирање):\n",
            "тетовски (долнополошки): 192\n",
            "скопскоцрногорски: 49\n",
            "кумановски: 771\n",
            "кривопаланечки: 173\n",
            "овчеполски: 7\n",
            "кратовски: 93\n",
            "скопски-велешки: 158\n",
            "кичевско-поречки: 350\n",
            "прилепско-битолски: 626\n",
            "гостиварски (горнополошки): 94\n",
            "галички: 21\n",
            "дебарски: 40\n",
            "вевчанско-радошки: 25\n",
            "струшки: 519\n",
            "охридски: 128\n",
            "горнопреспански: 54\n",
            "долнопреспански: 38\n",
            "тиквешко-мариовски: 248\n",
            "штипско-кочански: 228\n",
            "малешевско-пирински: 397\n",
            "гевгелиско-дојрански: 485\n",
            "струмичко-радовишки: 182\n",
            "дримколско-голобрдски: 97\n",
            "\n",
            "По нормализација (ретките во 'other'):\n",
            "тетовски (долнополошки): 192\n",
            "скопскоцрногорски: 49\n",
            "кумановски: 771\n",
            "кривопаланечки: 173\n",
            "овчеполски: 7\n",
            "кратовски: 93\n",
            "скопски-велешки: 158\n",
            "кичевско-поречки: 350\n",
            "прилепско-битолски: 626\n",
            "гостиварски (горнополошки): 94\n",
            "галички: 21\n",
            "дебарски: 40\n",
            "вевчанско-радошки: 25\n",
            "струшки: 519\n",
            "охридски: 128\n",
            "горнопреспански: 54\n",
            "долнопреспански: 38\n",
            "тиквешко-мариовски: 248\n",
            "штипско-кочански: 228\n",
            "малешевско-пирински: 397\n",
            "гевгелиско-дојрански: 485\n",
            "струмичко-радовишки: 182\n",
            "дримколско-голобрдски: 97\n",
            "Train: 3482 Val: 746 Test: 747\n",
            "Класи: ['вевчанско-радошки' 'галички' 'гевгелиско-дојрански' 'горнопреспански'\n",
            " 'гостиварски (горнополошки)' 'дебарски' 'долнопреспански'\n",
            " 'дримколско-голобрдски' 'кичевско-поречки' 'кратовски' 'кривопаланечки'\n",
            " 'кумановски' 'малешевско-пирински' 'овчеполски' 'охридски'\n",
            " 'прилепско-битолски' 'скопски-велешки' 'скопскоцрногорски'\n",
            " 'струмичко-радовишки' 'струшки' 'тетовски (долнополошки)'\n",
            " 'тиквешко-мариовски' 'штипско-кочански']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "SEGMENTED_PATH = \"/content/drive/MyDrive/dijalekti/texts_segmented.jsonl\"\n",
        "\n",
        "texts = []\n",
        "dialects = []\n",
        "\n",
        "with open(SEGMENTED_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        obj = json.loads(line)\n",
        "        t = (obj.get(\"text\") or \"\").strip()\n",
        "        d = (obj.get(\"dialect\") or \"\").strip()\n",
        "        if t != \"\" and d != \"\":\n",
        "            texts.append(t)\n",
        "            dialects.append(d)\n",
        "\n",
        "print(\"Вкупно сегменти:\", len(texts))\n",
        "\n",
        "cnt = Counter(dialects)\n",
        "print(\"Број сегменти по дијалект (пред филтрирање):\")\n",
        "for d, c in cnt.items():\n",
        "    print(f\"{d}: {c}\")\n",
        "\n",
        "# За да избегнеме проблеми со класи со 1 пример,\n",
        "# ги ставаме ретките во 'other'\n",
        "MIN_SAMPLES = 5\n",
        "dialects_norm = []\n",
        "for d in dialects:\n",
        "    if cnt[d] < MIN_SAMPLES:\n",
        "        dialects_norm.append(\"other\")\n",
        "    else:\n",
        "        dialects_norm.append(d)\n",
        "\n",
        "cnt2 = Counter(dialects_norm)\n",
        "print(\"\\nПо нормализација (ретките во 'other'):\")\n",
        "for d, c in cnt2.items():\n",
        "    print(f\"{d}: {c}\")\n",
        "\n",
        "le_seg = LabelEncoder()\n",
        "y_all = le_seg.fit_transform(dialects_norm)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    texts, y_all, test_size=0.3, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(X_train), \"Val:\", len(X_val), \"Test:\", len(X_test))\n",
        "print(\"Класи:\", le_seg.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocDssEg5Xsed",
        "outputId": "cb60e76f-901e-403b-8816-08e7ff3d1b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SEGMENTED TEXT MODEL – Validation ===\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         вевчанско-радошки       0.00      0.00      0.00         5\n",
            "                   галички       0.00      0.00      0.00         3\n",
            "      гевгелиско-дојрански       0.86      0.93      0.89        73\n",
            "           горнопреспански       0.67      0.33      0.44         6\n",
            "гостиварски (горнополошки)       0.89      0.44      0.59        18\n",
            "                  дебарски       0.00      0.00      0.00         5\n",
            "           долнопреспански       0.00      0.00      0.00         7\n",
            "     дримколско-голобрдски       0.60      0.40      0.48        15\n",
            "          кичевско-поречки       0.78      0.85      0.82        55\n",
            "                 кратовски       1.00      0.17      0.29        18\n",
            "            кривопаланечки       0.83      0.79      0.81        24\n",
            "                кумановски       0.78      0.98      0.87       132\n",
            "       малешевско-пирински       0.69      0.78      0.73        59\n",
            "                овчеполски       0.00      0.00      0.00         1\n",
            "                  охридски       0.83      0.25      0.38        20\n",
            "        прилепско-битолски       0.60      0.84      0.70        86\n",
            "           скопски-велешки       1.00      0.20      0.33        20\n",
            "         скопскоцрногорски       0.00      0.00      0.00         5\n",
            "       струмичко-радовишки       0.75      0.20      0.32        30\n",
            "                   струшки       0.50      0.84      0.63        67\n",
            "   тетовски (долнополошки)       0.95      0.58      0.72        31\n",
            "        тиквешко-мариовски       0.71      0.65      0.68        31\n",
            "          штипско-кочански       0.69      0.57      0.62        35\n",
            "\n",
            "                  accuracy                           0.71       746\n",
            "                 macro avg       0.57      0.43      0.45       746\n",
            "              weighted avg       0.72      0.71      0.68       746\n",
            "\n",
            "=== SEGMENTED TEXT MODEL – Test ===\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "         вевчанско-радошки       0.00      0.00      0.00         3\n",
            "                   галички       0.00      0.00      0.00         3\n",
            "      гевгелиско-дојрански       0.91      0.93      0.92        73\n",
            "           горнопреспански       1.00      0.20      0.33        10\n",
            "гостиварски (горнополошки)       0.75      0.30      0.43        10\n",
            "                  дебарски       0.00      0.00      0.00         7\n",
            "           долнопреспански       0.00      0.00      0.00         4\n",
            "     дримколско-голобрдски       0.71      0.36      0.48        14\n",
            "          кичевско-поречки       0.71      0.84      0.77        50\n",
            "                 кратовски       1.00      0.20      0.33        10\n",
            "            кривопаланечки       0.92      0.86      0.89        28\n",
            "                кумановски       0.72      0.98      0.83        99\n",
            "       малешевско-пирински       0.68      0.87      0.76        60\n",
            "                овчеполски       0.00      0.00      0.00         1\n",
            "                  охридски       1.00      0.39      0.56        18\n",
            "        прилепско-битолски       0.67      0.85      0.75       102\n",
            "           скопски-велешки       1.00      0.04      0.07        27\n",
            "         скопскоцрногорски       0.00      0.00      0.00        10\n",
            "       струмичко-радовишки       0.77      0.40      0.53        25\n",
            "                   струшки       0.55      0.87      0.67        89\n",
            "   тетовски (долнополошки)       0.73      0.41      0.52        27\n",
            "        тиквешко-мариовски       0.73      0.50      0.59        44\n",
            "          штипско-кочански       0.50      0.39      0.44        33\n",
            "\n",
            "                  accuracy                           0.70       747\n",
            "                 macro avg       0.58      0.41      0.43       747\n",
            "              weighted avg       0.71      0.70      0.66       747\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text_model_seg = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=7000,\n",
        "                              ngram_range=(1,2))),  # 1- и 2-gram\n",
        "    (\"clf\", LogisticRegression(max_iter=1500, n_jobs=-1))\n",
        "])\n",
        "\n",
        "text_model_seg.fit(X_train, y_train)\n",
        "\n",
        "# Валидација\n",
        "y_val_pred = text_model_seg.predict(X_val)\n",
        "print(\"=== SEGMENTED TEXT MODEL – Validation ===\")\n",
        "print(classification_report(\n",
        "    y_val, y_val_pred,\n",
        "    labels=list(range(len(le_seg.classes_))),\n",
        "    target_names=le_seg.classes_,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Тест\n",
        "y_test_pred = text_model_seg.predict(X_test)\n",
        "print(\"=== SEGMENTED TEXT MODEL – Test ===\")\n",
        "print(classification_report(\n",
        "    y_test, y_test_pred,\n",
        "    labels=list(range(len(le_seg.classes_))),\n",
        "    target_names=le_seg.classes_,\n",
        "    zero_division=0\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBQ2ZQeEf8F7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}